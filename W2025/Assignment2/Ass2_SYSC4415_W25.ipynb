{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0IFIr0wnxEFPE6RmBD05A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash3patel/SYSC4415/blob/main/Ass2_SYSC4415_W25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SYSC4415 Assignment 2 ‚Äì Fire Hydrant Detection üöí"
      ],
      "metadata": {
        "id": "8oJOR0w-jVsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "Special thanks to Nader Ibrahim for assembling the dataset. For more details, please refer to the paper:\n",
        "\n",
        "Ibrahim N, Dick K, Green JR. Computer Vision Fire Hydrant Obstruction Detection System. In2024 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE) 2024 Aug 6 (pp. 799-805). IEEE.\n",
        "\n",
        "\n",
        "Questions? Please use the Brightspace Discussion Board.\n",
        "\n",
        "Deadline: See Brightspace end date.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EVN5i-_rjZDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "DO NOT wait until the last minute to complete this assignment as training the models might take longer. Also leverage the free GPU provided by colab to make your training faster.\n",
        "\n",
        "\n",
        "Follow all steps carefully. Your solutions must be self-contained in this notebook. No other supplementary materials or files will be accepted. As soon as I open your notebook, I will click \"Runtime\" ‚Üí \"Run all\". Ensure your notebook runs without errors and displays results clearly.\n",
        "\n",
        "\n",
        "You are asked to provide both code and text to address discussion questions. For the text answers, see the markdown cells with the ‚ùì emoji for questions and enter your answers following the ‚úÖ emoji.\n",
        "\n",
        "Provide sufficient comments in your code to describe its functionality. Do not remove any necessary libraries as this will cause errors.\n",
        "\n",
        "Download the dataset from Brightspace and store it in your Google Drive under \"My Drive\" (not in any subfolder). Check the file location via right-click ‚Üí File Information ‚Üí Details ‚Üí Location.\n",
        "\n",
        "Submit your notebook as a `.ipynb` file named: `SYSC4415W25_A2_FIRSTNAME_LASTNAME_StudentID.ipynb` on Brightspace. No other submission methods will be accepted.\n"
      ],
      "metadata": {
        "id": "LOb5DLQSjeHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Provided on Brightspace.\n",
        "\n",
        "#### Dataset details:\n",
        "- Training Images: 2,272  \n",
        "- Validation Images: 563  \n",
        "- Labels: 0 = No Fire Hydrant, 1 = Fire Hydrant  \n",
        "- Imbalanced dataset (most images do not contain a hydrant).\n",
        "\n",
        "#### Dataset Information\n",
        "The dataset contains two main folders:\n",
        "- `train/`: Contains the training images and a CSV file with labels.\n",
        "- `valid/`: Contains the validation images and a CSV file with labels.\n",
        "\n",
        "Each folder includes:\n",
        "- Images of fire hydrants and non-fire hydrants.\n",
        "- A CSV file (`_classes.csv`) mapping each image filename to its label:\n",
        "  - `0` for no fire hydrant.\n",
        "  - `1` for fire hydrant.\n",
        "\n",
        "Ensure the zip file of the dataset (FH_detection_data.zip) to your Google Drive and placed under \"My Drive\" without any subfolders to keep the paths consistent.\n"
      ],
      "metadata": {
        "id": "Cwn5mt3sjeDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Steps\n",
        "\n",
        "### 1) Initial Setup\n",
        "Import necessary libraries\n"
      ],
      "metadata": {
        "id": "WBvkZqHoj-I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary libraries here\n",
        "\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "2XFcIUZp7vAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and unzip the dataset."
      ],
      "metadata": {
        "id": "O7OJ_TSI70uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Code provided by Akash. DO NOT CHANGE THIS CELL\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip /content/drive/MyDrive/FH_detection_data.zip -d /content/\n",
        "\n",
        "\n",
        "# Dataset path\n",
        "train_data_path = \"/content/train\"\n",
        "test_data_path = \"/content/valid\"\n",
        "train_label = pd.read_csv('/content/train/_classes.csv')\n",
        "test_label = pd.read_csv('/content/valid/_classes.csv')"
      ],
      "metadata": {
        "id": "EggsTjratyoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "HgQ8yflHuSpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Data Exploration\n",
        "1. Load dataset into a pandas DataFrame.\n",
        "2. Display display three sample images from each class\n",
        "3. Two Plots for class distribution of both train and test data\n",
        "[Requires 6 sample images (for two classes) and two plots of class distribution (train and test)]\n",
        "\n",
        "‚ùì Why is it important to check for class imbalance before training? How might this affect our model?  \n",
        "‚úÖ Your answer here\n",
        "..\n"
      ],
      "metadata": {
        "id": "xKsG1IKXj-F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "KYsEV2cjt9AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Uvr_OjehuWym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Preprocessing\n",
        "- Resize images to 128x128.\n",
        "- Apply any other necessary transformations that you feel can help.\n",
        "\n",
        "‚ùì Would one-hot encoding be necessary for binary classification? Why or why not?  \n",
        "‚úÖ Your answer here.."
      ],
      "metadata": {
        "id": "k57-IuKMuAsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "ErqFZKq9t-5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "OL2rFzw-u9V6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Baseline Model\n",
        "Create a CNN with:\n",
        "- Two convolutional layers to extract features from the images.\n",
        "- Max pooling layers after each convolution to reduce spatial dimensions.\n",
        "- Fully connected layers to perform classification.\n",
        "- A sigmoid activation function at the output layer to output a probability between 0 and 1.\n",
        "\n",
        "Required architecture:\n",
        "- Input: RGB images resized to 128x128 pixels.\n",
        "- Conv2d (3 input channels, 32 output channels, kernel size 3, padding 1)\n",
        "- MaxPool2d (kernel size 2, stride 2, padding 0) ‚Äì applied after the first Conv2d.\n",
        "- Conv2d (32 input channels, 64 output channels, kernel size 3, padding 1)\n",
        "- MaxPool2d (kernel size 2, stride 2, padding 0) ‚Äì applied after the second Conv2d.\n",
        "- Flatten\n",
        "- Linear layer with 128 units\n",
        "- Output Linear layer with 1 unit and sigmoid activation\n",
        "\n",
        "\n",
        "\n",
        "This model will be trained to classify whether an image contains a fire hydrant or not.\n",
        "\n",
        "\n",
        "‚ùì List three ways to improve the baseline model (e.g., adding dropout to reduce overfitting, using batch normalization to stabilize learning, or increasing the number of layers to capture more complex features). Provide a brief explanation for each.\n",
        "\n",
        "‚úÖ Your answer here.."
      ],
      "metadata": {
        "id": "vnzBOi2SuIp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "cd06Awp5vR0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "DzvEccoXvNBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Training and Evaluation\n",
        "Train your CNN using Binary Cross Entropy Loss and an Adam optimizer. Use a learning rate of 0.001. Iterate over your dataset for 10 epochs and track the loss.\n",
        "Evaluate using Precision, Recall, and F1-Score.\n",
        "\n",
        "‚ùì Explain why your chosen metric is most appropriate.  \n",
        "‚úÖ Your answer here\n",
        "\n",
        "\n",
        "Display the confusion matrix.\n",
        "\n",
        "‚ùì Explain the confusion matrix to a non-technical audience and relate it to your chosen metric.  \n",
        "‚úÖ Your answer here"
      ],
      "metadata": {
        "id": "bIYaYPvAj-Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "_MDIRPLkvX3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Sg2Z5VAOvZ0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6) Model Improvements\n",
        "Apply and evaluate three improvements that you mentioned in the Baseline CNN question (Step 4).\n",
        "\n",
        "‚ùì Which model would you deploy? Why?  \n",
        "‚úÖ Your answer here"
      ],
      "metadata": {
        "id": "uNSOIyZ6j9_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "Vduzdusiwtha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "MRzoK-N66b6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Personal Inference Test\n",
        "Test your trained model on new images (either collected using a camera or collected from the internet). Predict whether each image contains a fire hydrant and print the result.\n",
        "\n",
        "Of your five images:\n",
        "- Include at least one image of a fire hydrant that your model does not detect correctly.\n",
        "- Include at least one image of a fire hydrant that your model does detect correctly.\n",
        "\n",
        "‚ùì Explain why you believe your model performed the way it did on each of your five images. What patterns or mistakes do you observe?\n",
        "‚úÖ Your answer here\n"
      ],
      "metadata": {
        "id": "UakltCgMDXVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your code here.."
      ],
      "metadata": {
        "id": "l9MpLZTXECRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nY68Zn9OEWVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) Final Thoughts\n",
        "‚ùì How would you improve the model in the future?\n",
        "\n",
        "‚úÖ Your answer here..\n"
      ],
      "metadata": {
        "id": "Zp6zfAfP6b4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----"
      ],
      "metadata": {
        "id": "1Ey8xW2D6lR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Question:\n",
        "### ‚ùì Did you use AI in completing your assignment. If yes, what AI tool you use and how did you prompt it and how you validate the response.\n",
        "\n",
        "‚úÖ Your answer here..\n"
      ],
      "metadata": {
        "id": "_Jn3fsmQj97D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "l8IF1HLREaja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "Submit your `.ipynb` notebook on Brightspace using the following name format:  \n",
        "`SYSC4415W25_A2_FIRSTNAME_LASTNAME_StudentID.ipynb`\n",
        "\n"
      ],
      "metadata": {
        "id": "YIMUz6vvj94K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Lew5EKNjScc"
      },
      "outputs": [],
      "source": []
    }
  ]
}